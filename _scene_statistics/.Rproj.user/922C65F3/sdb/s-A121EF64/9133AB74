{
    "collab_server" : "",
    "contents" : "#' Import human data from raw text.\nget_human_responses <-\n  function(path = '~/Dropbox/Calen/Work/occluding/detection_model/_data/exported/human_data.txt') {\n    library(dplyr)\n    library(tidyr)\n    \n    bin_values <- get_experiment_bin_values()\n    \n    human_data <- read.table(path, sep = \"\\t\", header = T)\n    \n    human_data <- human_data %>% filter(!SUBJECT %in% c(\"jsa\",\n                                                        \"yhb\"), TRIAL != 1) %>%\n      rename(BIN = BINS)\n    \n    #human_data <- human_data %>% group_by(SUBJECT, BIN, TARGET) %>%\n    #  mutate(n_ecc = length(unique((ECCENTRICITY)))) %>% filter(!(SESSION ==\n    #                                                                2 & n_ecc > 5))\n    \n    human_data$CORRECT <-\n      ifelse(human_data$HIT == 1 | human_data$CORRECTREJECTION ==\n               1, 1, 0)\n    \n    human_data$BIN <- factor(human_data$BIN)\n    \n    human_data <-\n      merge(human_data, bin_values) %>% arrange(SUBJECT,\n                                                TARGET, BIN, statType, SESSION, ECCENTRICITY)\n    \n    return(human_data)\n  }\n\n#' Produce a data frame from the raw data that contains summary statistics.\nget_human_detect <- function(human_data) {\n  if (missing(human_data)) {\n    error(\"Missing human data\")\n  }\n  experiment_bin_values <- get_experiment_bin_values()\n  \n  human_detect <- human_data %>%\n    group_by(SUBJECT, ECCENTRICITY, BIN, TARGET) %>%\n    summarize(\n      hit = sum(HIT == 1) / (sum(HIT == 1) + sum(MISS == 1)),\n      miss = sum(MISS == 1) / (sum(MISS == 1) + sum(HIT == 1)),\n      falsealarm = sum(FALSEALARM == 1) / (sum(FALSEALARM == 1) + sum(CORRECTREJECTION == 1)),\n      correctrejection = sum(CORRECTREJECTION == 1) / (sum(CORRECTREJECTION == 1) + sum(FALSEALARM == 1)),\n      percent_correct = mean(CORRECT)\n    ) %>% mutate(\n      hit_adj = ifelse(hit == 0, 1 / 1200, ifelse(hit == 1, 1199 / 1200, hit)),\n      falsealarm_adj = ifelse(\n        falsealarm == 0,\n        1 / 1200,\n        ifelse(falsealarm == 1, 1199 / 1200, falsealarm)\n      ),\n      percent_correct_adj = ifelse(percent_correct == 1, 2399 / 2400, percent_correct),\n      percent_correct_adj = ifelse(percent_correct == 0, 1 / 2400, percent_correct)\n    ) %>%\n    mutate(dprime = qnorm(hit_adj) - qnorm(falsealarm_adj)) %>%\n    mutate(bias = dprime / 2 - qnorm(hit_adj)) %>%\n    merge(., experiment_bin_values, by = c(\"BIN\", \"TARGET\")) %>%\n    rename(eccentricity = ECCENTRICITY) %>%\n    arrange(SUBJECT, BIN, TARGET, eccentricity, percent_correct) %>%\n    data.frame()\n  \n  human_detect$TARGET <-\n    factor(\n      human_detect$TARGET,\n      levels = c(\"vertical\", \"horizontal\", \"bowtie\", \"spot\"),\n      ordered = T\n    )\n  \n  human_detect        <- human_detect %>%\n    arrange(SUBJECT, statType, TARGET, BIN, eccentricity)\n  \n  return(human_detect)\n}\n\n# Compute summary statistics for the model from the raw responses\nget_model_detect <- function(model_data) {\n  experiment_bin_values <- get_experiment_bin_values()\n  \n  model_detect <- model_data %>%\n    group_by(SUBJECT, ECCENTRICITY, BIN, TARGET) %>%\n    summarize(\n      hit = sum(HIT == 1) / (sum(HIT == 1) + sum(MISS == 1)),\n      miss = sum(MISS == 1) / (sum(MISS == 1) + sum(HIT == 1)),\n      falsealarm = sum(FALSEALARM == 1) / (sum(FALSEALARM == 1) + sum(CORRECTREJECTION == 1)),\n      correctrejection = sum(CORRECTREJECTION == 1) / (sum(CORRECTREJECTION == 1) + sum(FALSEALARM == 1)),\n      percent_correct = mean(CORRECT)\n    ) %>% mutate(\n      hit_adj = ifelse(hit == 0, 1 / 1200, ifelse(hit == 1, 1199 / 1200, hit)),\n      falsealarm_adj = ifelse(\n        falsealarm == 0,\n        1 / 1200,\n        ifelse(falsealarm == 1, 1199 / 1200, falsealarm)\n      ),\n      percent_correct_adj = ifelse(percent_correct == 1, 2399 / 2400, percent_correct),\n      percent_correct_adj = ifelse(percent_correct == 0, 1 / 2400, percent_correct)\n    ) %>%\n    mutate(dprime = (qnorm(hit_adj) - qnorm(falsealarm_adj))) %>%\n    mutate(bias = dprime / 2 - qnorm(hit_adj)) %>%\n    merge(., experiment_bin_values, by = c(\"BIN\", \"TARGET\")) %>%\n    rename(eccentricity = ECCENTRICITY) %>%\n    arrange(SUBJECT, BIN, TARGET, eccentricity, percent_correct) %>%\n    data.frame()\n  \n  model_detect$TARGET <-\n    factor(\n      model_detect$TARGET,\n      levels = c(\"vertical\", \"horizontal\", \"bowtie\", \"spot\"),\n      ordered = T\n    )\n  \n  model_detect        <- model_detect %>%\n    arrange(SUBJECT, statType, TARGET, BIN, eccentricity)\n  \n  return(model_detect)\n}\n\n#' Add thresholds to a dataframe that contains psychometric parameters\nget_threshold <- function(psychometric_parameters) {\n  thresholds <- psychometric_parameters %>%\n    rowwise() %>%\n    mutate(threshold = ((d0 *\n                           e0 ^ b) / 1 - e0 ^ b) ^ (1 / b))\n  \n  return(thresholds)\n}\n\n#' Plot thresholds measured from the human and ideal performance.\nplot_publication_thresholds <-\n  function(human.thresholds,\n           model.thresholds,\n           out_path = \"~/Dropbox/Calen/Dropbox/\",\n           statIn = \"Lvals\") {\n    \n    human.thresholds <- human.thresholds %>%\n      mutate(TARGET = factor(TARGET, levels = c(\"vertical\", \"horizontal\", \"bowtie\", \"spot\")))\n    \n    model.thresholds <- model.thresholds %>%\n      mutate(TARGET = factor(TARGET, levels = c(\"vertical\", \"horizontal\", \"bowtie\", \"spot\")))\n    library(ggthemes)\n    \n    human.threshold.1 <- human.thresholds %>%\n      group_by(TARGET, BIN, SUBJECT) %>%\n      summarize(threshold = mean(threshold)) %>%\n      select(TARGET, BIN, threshold, SUBJECT) %>%\n      data.frame\n    \n    model.threshold.1 <- model.thresholds %>%\n      select(TARGET, BIN, threshold, SUBJECT) %>%\n      data.frame\n    \n    threshold_values <-\n      rbind(model.threshold.1, human.threshold.1) %>%\n      data.frame\n    \n    bin_values <- get_experiment_bin_values()\n    d.1 <- merge(threshold_values, bin_values) %>%\n      group_by(TARGET, BIN, statValue, statType, SUBJECT) %>%\n      summarize(threshold = mean(threshold)) %>%\n      filter(statType == statIn)\n    \n    \n    t.1.plot <-\n      ggplot(data = d.1, aes(x = statValue, y = threshold,\n                             colour = SUBJECT, group = SUBJECT)) +\n      geom_point() +\n      geom_line() +\n      facet_wrap( ~ TARGET) +\n      theme_light() +\n      theme(aspect.ratio = 1) +\n      ylab(\"Eccentricity Threshold\")\n    \n    if (statIn == \"Lvals\") {\n      t.1.plot <- t.1.plot + expand_limits(x = 0,\n                                           y = c(5, 23)) + xlab(\"Background Luminance\")\n    } else if (statIn == \"Cvals\") {\n      t.1.plot <- t.1.plot + expand_limits(x = 0,\n                                           y = 1) + xlab(\"Background Contrast\")\n    } else if (statIn == \"Svals\") {\n      t.1.plot <- t.1.plot + xlim(0.4, 0.9) +\n        expand_limits(x = 0, y = 0.9) + xlab(\"Background Similarity\")\n    }\n    plot(t.1.plot)\n    ggsave(t.1.plot, file = paste0(out_path, statIn, \"_thresholds.pdf\"))\n  }\n",
    "created" : 1525452062501.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2194510589",
    "id" : "9133AB74",
    "lastKnownWriteTime" : 1525633254,
    "last_content_update" : 1525633254,
    "path" : "~/Dropbox/Calen/Work/occluding/detection_model_analysis/_human/human_psychometrics.R",
    "project_path" : null,
    "properties" : {
        "docOutlineVisible" : "1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}